Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
8000,0.0,0.3799999952316284,0.44499996304512024,0.3799999952316284,0.4449999928474426,0.4864305795791322,0.47724393916513186,0.4864614200213154,0.47725430332875196
8000,500,0.19219867903739213,0.2120010707113478,0.20375000005587934,0.22366666595141094,0.2002514132565384,0.21916283784771864,0.20573009506978815,0.22536771988576332
8000,1000,0.16859915340319276,0.18909786691268285,0.18549999995157124,0.2069999999470181,0.15946011656697562,0.1952974075868782,0.16887732301858135,0.20537759378907483
8000,2000,0.13020003447309136,0.16596066024568346,0.16050000032410025,0.2011111103826099,0.1299500294133175,0.17813986697004455,0.15016139221163083,0.20176921303803466
8000,4000,0.09008487756364048,0.1330070714155833,0.13699999982491134,0.19366666542159186,0.09097175208503977,0.14523306164027286,0.13066987894470136,0.19464445723976215
8000,8000,0.06452561211772263,0.12156254996856054,0.10049999938346446,0.18855555521117318,0.0601621104177614,0.1276445236718546,0.0929015954898967,0.18677175220206668
8000,16000,0.04486861601471901,0.11318359524011612,0.07400000006891787,0.1835555558403333,0.037388543632273445,0.11818103341028428,0.05743058814805963,0.18257755035861517
8000,32000,0.038445246894843875,0.10018367634879219,0.05262499963864684,0.17055555681387582,0.0300879180964888,0.10581375188723807,0.03845364617435594,0.17037213884981664
8000,64000,0.03199770820792765,0.09090833912293116,0.0343749996740371,0.1582222228248914,0.02401208100018251,0.0960831528425698,0.021067328641034562,0.16473010578271466

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN1L
  - Number of hidden layers: 1
  - Width of hidden layers: 500
  - Dataset type: cifar10
  - Random labels: False
  - Training set size: 8000
  - Test set size: 9000
  - Minimum epochs: 4000
  - Number of Batches: 80
  - Beta values: [0.0, 500, 1000, 2000, 4000, 8000, 16000, 32000, 64000]
  - Learning rate (a0): 0.005
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
