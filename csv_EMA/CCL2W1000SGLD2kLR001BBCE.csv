Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
2000,0.0,0.541500025242567,0.5686667011843787,0.5415000021457672,0.5686666631036335,0.5038326461167895,0.5044933313464224,0.5038327137554199,0.5044933147176052
2000,125,0.4965000256896019,0.4415555685758591,0.4964999981224537,0.44155555102560257,0.4026519243663281,0.5252830992945843,0.40270973799740095,0.525289590900443
2000,250,0.30292018577456475,0.2905351397063997,0.3030000012367964,0.29077777796321447,0.356509721378315,0.36063354134856457,0.35654994731250245,0.3607346456869501
2000,500,0.23043800983577967,0.2521715410881572,0.2305000001564622,0.25233333392275703,0.274187822943706,0.2840387534998736,0.27428506381093937,0.28413851701181647
2000,1000,0.21978450752794743,0.2519674370686213,0.22050000000745057,0.25266666611035665,0.21301076447106762,0.25518462397012637,0.21328993813240843,0.25575367531586274
2000,2000,0.14688013950362802,0.20473458551698262,0.14900000095367433,0.2065555553469393,0.15513171389875663,0.2194108071783095,0.1560886492318984,0.22046496555637474
2000,4000,0.06807919493876398,0.20268402414189446,0.07199999894946814,0.20766666614347035,0.07385993168300575,0.20577483393854265,0.0767607630660991,0.20983837887239332
2000,8000,0.01653482667256867,0.20252733611398274,0.02149999951943755,0.2193333332737287,0.022286598497776807,0.21004469624359234,0.026285082035094907,0.22103726361468365
2000,16000,0.011815736769486307,0.18990858362780677,0.01699999962002039,0.20944444297088516,0.005566055178881964,0.19901470790545353,0.006928664655172047,0.21739029836875232

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN2L
  - Number of hidden layers: 2
  - Width of hidden layers: 1000
  - Dataset type: cifar10
  - Random labels: False
  - Training set size: 2000
  - Test set size: 9000
  - Minimum epochs: 4000
  - Number of Batches: 40
  - Beta values: [0.0, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
  - Learning rate (a0): 0.01
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
"
