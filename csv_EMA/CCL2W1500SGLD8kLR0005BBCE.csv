Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
8000,0.0,0.5399999618530273,0.5800000429153442,0.5400000214576721,0.5799999833106995,0.505345230339007,0.5014473431911174,0.5053452333417301,0.5014473205366786
8000,500,0.2207748519256711,0.25480049782329134,0.22199999913573265,0.25611110859447056,0.2457091680491724,0.23985741502198743,0.24608042907703817,0.24029059761746507
8000,1000,0.20370292188599706,0.20947663684686024,0.2054999995045364,0.21100000010596381,0.200606517004623,0.22252063940383304,0.20144495613088034,0.22346233520080044
8000,2000,0.15427097529172898,0.20858427319261763,0.15737500013783573,0.2116666658057107,0.17408966377379423,0.20326777975723923,0.1759147161233567,0.20512941720849465
8000,4000,0.10625328402966261,0.17639331105682585,0.1180000001564622,0.19144444366296132,0.1152171097732433,0.17800053501875385,0.12088488996249669,0.1857761759794393
8000,8000,0.061675865086726844,0.14350688076681561,0.08812499984633178,0.19244444535838234,0.05984893035332411,0.16681462328680063,0.0755725544159163,0.1935285378679515
8000,16000,0.025468351889867336,0.14420499619510438,0.03812499961350113,0.19022222293747795,0.022901510003655905,0.15456685595079747,0.03485059633168111,0.19034478420966464
8000,32000,0.012517140328418464,0.12887410405609342,0.014249999704770745,0.17788888927963045,0.010398589386292838,0.14020410561249827,0.012789198281883577,0.18265029319630963
8000,64000,0.008334741269936784,0.11777678612205718,0.003124999930150807,0.1697777776254548,0.006782925550033886,0.12448679988360997,0.0034949993884029465,0.17186516680416625

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN2L
  - Number of hidden layers: 2
  - Width of hidden layers: 1500
  - Dataset type: cifar10
  - Random labels: False
  - Training set size: 8000
  - Test set size: 9000
  - Minimum epochs: 4000
  - Number of Batches: 80
  - Beta values: [0.0, 500, 1000, 2000, 4000, 8000, 16000, 32000, 64000]
  - Learning rate (a0): 0.005
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
