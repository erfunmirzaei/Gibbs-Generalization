Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
8000,64000,0.0030444715452176752,0.09967105065782865,0.002124999952502549,0.14222222268581391,0.002566384558777126,0.10136862581645754,0.0020136093444879993,0.14149274398032535

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN3L
  - Number of hidden layers: 3
  - Width of hidden layers: 1000
  - Dataset type: cifar10
  - Random labels: False
  - Training set size: 8000
  - Test set size: 9000
  - Minimum epochs: 4000
  - Number of Batches: 80
  - Beta values: [64000]
  - Learning rate (a0): 0.005
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0]
"
