Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
8000,0.0,0.4099999666213989,0.4899999499320984,0.4099999964237213,0.49000000953674316,0.5029175365535806,0.5105375228240299,0.5029175167471878,0.5105375222137565
8000,500,0.2174103118479252,0.22495325737529331,0.22812500102445482,0.234666665063964,0.2576960499722417,0.29379614623911404,0.2579813109821642,0.2939522674515067
8000,1000,0.2055449303239584,0.24358630908860102,0.2074999999254942,0.2452222228050232,0.28970793129350064,0.27388035309438125,0.2900415180361457,0.274080797067106
8000,2000,0.1667132587172091,0.25016405913564893,0.17062500016763807,0.25455555220445,0.199330092694676,0.2165211529291405,0.1999933257845525,0.21727739361059464
8000,4000,0.11849041050300002,0.17300151040156683,0.13049999983049929,0.18899999923176236,0.13920757960275018,0.1792431779187704,0.1430829635832613,0.18353885360645897
8000,8000,0.06471207125578075,0.15179266184568405,0.0887500002514571,0.1848888890610801,0.06322208182581693,0.1810990365844032,0.0740731214082742,0.19881987427723766
8000,16000,0.03439625125320163,0.14953722970353234,0.05449999971315265,0.18799999985429977,0.022066798188370196,0.1572992129616555,0.032320822725381455,0.18801649337886062
8000,32000,0.014710216590901836,0.13457231786515977,0.018249999708496036,0.18411111103163824,0.013949922245239088,0.16068526893902327,0.0200875599506854,0.20071523084947274
8000,64000,0.010473105727578513,0.12120075093375313,0.006999999843537807,0.17711111174689398,0.007660472012312052,0.13316972377510378,0.00720215741317004,0.17820347526628325

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN3L
  - Number of hidden layers: 3
  - Width of hidden layers: 1000
  - Dataset type: cifar10
  - Random labels: False
  - Training set size: 8000
  - Test set size: 9000
  - Minimum epochs: 4000
  - Number of Batches: 80
  - Beta values: [0.0, 500, 1000, 2000, 4000, 8000, 16000, 32000, 64000]
  - Learning rate (a0): 0.005
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
