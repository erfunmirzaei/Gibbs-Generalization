Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
8000,0.0,0.4599774479866028,0.5649999976158142,0.46000000834465027,0.5649999976158142,0.5018139047232155,0.494670408177694,0.5018388049240445,0.4946831898054145
8000,500,0.3937312878668308,0.43684205876456367,0.45624999776482583,0.49677777422799,0.44531657177859496,0.4750883692234423,0.46669457254046787,0.4983098446764537
8000,1000,0.30558190736919644,0.3593319594860077,0.44687499664723873,0.5061111072699229,0.37430874172222656,0.43791367843612816,0.4412009476988812,0.5059583115206654
8000,2000,0.22392650619149207,0.25677428344885506,0.4432499960064888,0.49799999925825333,0.2460985596227774,0.29631694951364373,0.42846581703149306,0.4984695378394029
8000,4000,0.18684985283762218,0.22839436100588906,0.4172499984502792,0.5018888877497779,0.19846006743772004,0.23853266416635494,0.42266889064319413,0.5011649252384709
8000,8000,0.16163559816777706,0.21393982072671255,0.3677500009536743,0.49977777732743156,0.1603947788134935,0.22248580694905953,0.3545401850397356,0.49495437725890185
8000,16000,0.12219948908314109,0.23764969971444871,0.24975000005215406,0.49066666695806715,0.10928741491028107,0.2585497106585967,0.21548744248842355,0.49318643553920505
8000,32000,0.04459280585870147,0.3106153365638521,0.05974999978207052,0.5009999977217781,0.035597715272934066,0.3268674572319166,0.04083843924255544,0.49444127724688564
8000,64000,0.028855151636525987,0.30222224957413146,0.01687499969266355,0.4925555533832974,0.022878675673321677,0.316567390350039,0.010543610505464889,0.4957328839102065

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN1L
  - Number of hidden layers: 1
  - Width of hidden layers: 500
  - Dataset type: cifar10
  - Random labels: True
  - Training set size: 8000
  - Test set size: 9000
  - Minimum epochs: 4000
  - Number of Batches: 80
  - Beta values: [0.0, 500, 1000, 2000, 4000, 8000, 16000, 32000, 64000]
  - Learning rate (a0): 0.005
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
