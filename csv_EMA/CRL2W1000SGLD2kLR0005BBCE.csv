Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
2000,0.0,0.4955000214278698,0.502666691939036,0.4954999998211861,0.5026666614744398,0.5004075860534256,0.5006228351787076,0.50040765146659,0.5006229615181711
2000,125,0.48449995219707487,0.5002361863851548,0.4844999976456165,0.5002222183677886,0.5077262703813318,0.5004430161049819,0.5077488172198632,0.500445038693704
2000,250,0.45381648913025857,0.5044080058733622,0.4555000014603138,0.5053333299027549,0.4694129906736047,0.5087730284677664,0.46958595582114987,0.509303131236935
2000,500,0.4318934105336666,0.49015751977761585,0.43799999803304673,0.4948888854848014,0.43591893412077987,0.49474250154083477,0.4384269443059154,0.4977324122962724
2000,1000,0.30393300727009775,0.4740844815969467,0.3214999992400408,0.4962222201956643,0.3447890908642855,0.4990241711245829,0.35000503339909567,0.5062999311284696
2000,2000,0.14761099889874457,0.4684559226036072,0.16550000067800283,0.48988888627953,0.16841245513124162,0.4827419216523995,0.18042037603534988,0.49819268243283793
2000,4000,0.053630655026063324,0.4468471778763665,0.0754999996162951,0.4925555527210236,0.04626924373102444,0.46618485231604107,0.05869178828181909,0.5004230718162068
2000,8000,0.018849846604280174,0.39670374956395893,0.02899999963119626,0.4938888861073388,0.01725704853898232,0.42584799343292934,0.026027216535889037,0.49858229802156384
2000,16000,0.006437661487143487,0.3969222393300798,0.0034999999217689036,0.49722221824857926,0.008716292242350954,0.41398995473901035,0.009031236867595376,0.49459205625200164

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN2L
  - Number of hidden layers: 2
  - Width of hidden layers: 1000
  - Dataset type: cifar10
  - Random labels: True
  - Training set size: 2000
  - Test set size: 9000
  - Minimum epochs: 4000
  - Number of Batches: 40
  - Beta values: [0.0, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
  - Learning rate (a0): 0.005
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
"
