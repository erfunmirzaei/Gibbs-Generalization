Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
2000,0.0,0.49550002813339233,0.49799996614456177,0.49549999833106995,0.49799999594688416,0.5004030301960244,0.5008138078502037,0.5004030921330397,0.5008137968316432
2000,125,0.4555191993713379,0.5011102457841238,0.4555000066757202,0.5011666516462961,0.45594993400832784,0.49516687610525406,0.455976174229747,0.49520947635084883
2000,250,0.4150022566318512,0.5043468872706095,0.41499999165534973,0.5046666661898295,0.41783195827582154,0.5065666576475143,0.41789683408575024,0.5066440480857562
2000,500,0.34705767035484314,0.4922681252161662,0.3474999964237213,0.49258333444595337,0.3454513116040984,0.4941487282301765,0.34583048609265515,0.49457398207548847
2000,1000,0.2246541976928711,0.4942226807276408,0.226500004529953,0.4949166675408681,0.21263898377725265,0.4947078378589315,0.2136584884262925,0.49588910712275264
2000,2000,0.07449271529912949,0.4998069802920024,0.07800000160932541,0.50450000166893,0.07200820995230525,0.4994669345736764,0.07471965545568311,0.5042187106826531
2000,4000,0.008679397404193878,0.4786626100540161,0.012500000186264515,0.5005833506584167,0.022936030816710827,0.4788320628756579,0.029197083465942016,0.4988284409143625
2000,8000,0.004251671023666859,0.45187585552533466,0.004000000189989805,0.5031666656335195,0.0179713518933431,0.4529104454675895,0.023405486098820122,0.5010575742607933
2000,16000,0.005288513842970133,0.4008675118287404,0.0005000000237487257,0.4949166576067607,0.009375254114109142,0.4061716941145517,0.007201652023166258,0.4985262295183723

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN2L
  - Number of hidden layers: 2
  - Width of hidden layers: 1000
  - Dataset type: cifar10
  - Random labels: True
  - Training set size: 2000
  - Test set size: 9000
  - Minimum epochs: 4000
  - Number of Batches: 1
  - Beta values: [0.0, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
  - Learning rate (a0): 0.01
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
"
