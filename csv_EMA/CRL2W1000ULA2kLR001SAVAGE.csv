Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
2000,0.0,0.49549999833106995,0.49799999594688416,0.49549999833106995,0.49799999594688416,0.5004030644275075,0.5008137876141887,0.5004030921330397,0.5008137968316432
2000,125,0.4950000047683716,0.5047521789868673,0.4950000047683716,0.5047500133514404,0.4921823131676548,0.5050206737740537,0.49218483113100947,0.5050330689411472
2000,250,0.476500004529953,0.5052502552668253,0.476500004529953,0.5052500069141388,0.47765600908652567,0.5059504305611433,0.47767503542066164,0.505958208284701
2000,500,0.46050146222114563,0.4965514540672302,0.46050000190734863,0.49683334430058795,0.4577370316396214,0.5004272361516832,0.45785223018206805,0.5005489017660869
2000,1000,0.4142419993877411,0.49664296706517536,0.41449999809265137,0.49716665347417194,0.41091644552628553,0.49451703100319894,0.4112482044915039,0.4949433314579566
2000,2000,0.3015758991241455,0.49184102813402814,0.3019999861717224,0.4923333326975505,0.30233508264042086,0.49326524296360275,0.3031917777606779,0.4943358321774863
2000,4000,0.1726393848657608,0.4862706959247589,0.1770000010728836,0.4904166559378306,0.16523148067468973,0.48632893580548736,0.1682958779771039,0.49022495915634207
2000,8000,0.07630996406078339,0.4879439075787862,0.0885000005364418,0.4997499982515971,0.05322366001923266,0.4925089223262677,0.059622143375599394,0.5055356730259994
2000,16000,0.014331215061247349,0.4601077735424042,0.01549999974668026,0.49925000468889874,0.01858625143140354,0.45943989766612486,0.02231152517347809,0.49516073786852344

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: Savage
  - l_max: 4.0
  - Network architecture: FCN2L
  - Number of hidden layers: 2
  - Width of hidden layers: 1000
  - Dataset type: cifar10
  - Random labels: True
  - Training set size: 2000
  - Test set size: 9000
  - Minimum epochs: 4000
  - Number of Batches: 1
  - Beta values: [0.0, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
  - Learning rate (a0): 0.01
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
"
