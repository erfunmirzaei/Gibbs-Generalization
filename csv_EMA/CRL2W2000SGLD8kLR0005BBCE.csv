Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
8000,0.0,0.47999998927116394,0.4949999749660492,0.47999998927116394,0.4950000047683716,0.5068477692815944,0.5025194579784866,0.5068477467594239,0.5025194510420931
8000,500,0.4997686505317688,0.493786672088835,0.49999999850988386,0.49377777642673915,0.49746328486022856,0.504587545149901,0.49749523835336956,0.5046737666523013
8000,1000,0.46686965934932234,0.4949601451555888,0.47374999709427357,0.5011111093891991,0.49827580837938673,0.4931138069763355,0.4983398307109723,0.4932120004575731
8000,2000,0.356662960536778,0.4224217865202162,0.42537499852478505,0.4951111117998759,0.4284803996605927,0.4942657844687655,0.43796735636049633,0.503886894228894
8000,4000,0.2768334697932005,0.39257946809132893,0.39749999791383744,0.5004444440205892,0.2976820761437138,0.4593143727027141,0.332441916749684,0.49692989982522084
8000,8000,0.16017782175913453,0.4008382750882043,0.22812500009313225,0.5084444397025638,0.14630776444119062,0.4438089456910362,0.1850330610458468,0.5023337127580172
8000,16000,0.12597552621737124,0.3136850171618991,0.23737499983981253,0.5020000007417467,0.08319753243434908,0.3768533793068565,0.13927343365170203,0.5055336633620389
8000,32000,0.09275999069213867,0.26174466609954833,0.1717500004451722,0.4962222238381704,0.055298532371605015,0.3270995013021891,0.09245469972680127,0.4961736745454383
8000,64000,0.07515415758825839,0.24234168595737882,0.11262499967124313,0.4993333293331994,0.04222940972464414,0.302195789464138,0.05613781804402612,0.4950335060661981

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN2L
  - Number of hidden layers: 2
  - Width of hidden layers: 2000
  - Dataset type: cifar10
  - Random labels: True
  - Training set size: 8000
  - Test set size: 9000
  - Minimum epochs: 4000
  - Number of Batches: 80
  - Beta values: [0.0, 500, 1000, 2000, 4000, 8000, 16000, 32000, 64000]
  - Learning rate (a0): 0.005
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
