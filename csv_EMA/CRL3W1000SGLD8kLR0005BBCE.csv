Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
8000,0.0,0.5200001001358032,0.4899999499320984,0.5199999809265137,0.49000000953674316,0.5024025150655637,0.5023096306349303,0.5024024901773364,0.5023096278578164
8000,500,0.4936998154968023,0.4886693365044064,0.4963749941438437,0.49833333161142135,0.5003238249557743,0.5070942058694533,0.5003238222297758,0.5070957034215502
8000,1000,0.37718231976032257,0.4101835442913903,0.46949999779462814,0.5034444431463877,0.49905336239885023,0.5066601536214682,0.4990533437759601,0.5066603798743684
8000,2000,0.1794399566948414,0.18073031736744774,0.4893749956041574,0.48944444259007774,0.42123146627937735,0.47554289558342716,0.44046367251776325,0.49395941218448564
8000,4000,0.239587870426476,0.32446963058577644,0.37674999944865706,0.49533333116107514,0.26544906347362296,0.4482256347414016,0.3107516300845646,0.49840195907780843
8000,8000,0.1535213199444115,0.28837217191855113,0.28225000090897084,0.49722222089767454,0.12594668417168853,0.38750523139297666,0.19783335509975153,0.4973711134665158
8000,16000,0.08903288263827562,0.29806768231921726,0.1640000006183982,0.4931111084090339,0.06631233991037495,0.372749555336113,0.11701568917906906,0.49611619749803315
8000,32000,0.11160896476358176,0.2444397615061866,0.21387499971315266,0.500222220023473,0.06152170933312297,0.3163417219323278,0.10324739748448329,0.4937819765716117
8000,64000,0.0949226356111467,0.21878130866421594,0.15912500005215408,0.49633333285649617,0.03698834552308033,0.32137428877739294,0.04636149092872708,0.49469628354262984

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN3L
  - Number of hidden layers: 3
  - Width of hidden layers: 1000
  - Dataset type: cifar10
  - Random labels: True
  - Training set size: 8000
  - Test set size: 9000
  - Minimum epochs: 4000
  - Number of Batches: 80
  - Beta values: [0.0, 500, 1000, 2000, 4000, 8000, 16000, 32000, 64000]
  - Learning rate (a0): 0.005
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
