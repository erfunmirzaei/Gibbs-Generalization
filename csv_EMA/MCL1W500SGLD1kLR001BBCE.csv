Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
1000,0.0,0.699999988079071,0.47999998927116394,0.699999988079071,0.47999998927116394,0.5041151336243029,0.49222569897607443,0.5042126237900131,0.49228415092998346
1000,125,0.1738939866423607,0.23512081862712392,0.1769999995827675,0.23869957333924818,0.16489732190867798,0.24641217258826442,0.16799773715929703,0.2497725444262804
1000,250,0.10580297522246837,0.20566569397948226,0.1089999994263053,0.21075937357179972,0.10536749450942587,0.21073550221201026,0.1092948625275212,0.21604030375585825
1000,500,0.049401285914487406,0.17046533585811147,0.055999999307096,0.1790768874391001,0.05081247609519165,0.16318750763673934,0.05478903499028588,0.1724899532461107
1000,1000,0.01482811310852412,0.14581732672392106,0.018999999575316905,0.16052206902175534,0.015102085670222538,0.15047665221117296,0.01948933378900728,0.16358027278324122
1000,2000,0.005726442659215536,0.14003212301402676,0.011999999731779098,0.165659706203305,0.005147276188043544,0.14802172690330595,0.00646529897430945,0.1729415741113336
1000,4000,0.001841504110052483,0.11756397760948356,0.0,0.14467252038267195,0.0023994122760342585,0.1315109432280768,0.0013306936116686764,0.16102817948023707
1000,8000,0.0016183187850401736,0.1083326279660877,0.0,0.14025154227048767,0.0011903824697763689,0.11114657578313532,0.00015246853948696617,0.14179586291880847
1000,16000,0.0010981539919157513,0.09451559368444949,0.0,0.12965590848910566,0.001137010452604655,0.09421556254089794,3.073043817304894e-11,0.12725217583330037

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN1L
  - Number of hidden layers: 1
  - Width of hidden layers: 500
  - Dataset type: mnist
  - Random labels: False
  - Training set size: 1000
  - Test set size: 9786
  - Minimum epochs: 4000
  - Number of Batches: 20
  - Beta values: [0.0, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
  - Learning rate (a0): 0.01
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
