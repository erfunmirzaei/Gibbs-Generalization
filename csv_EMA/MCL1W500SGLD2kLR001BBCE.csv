Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
2000,0.0,0.5600000619888306,0.6499999165534973,0.5600000023841858,0.6499999761581421,0.4955837743499411,0.5059372485344681,0.4957283176098505,0.5060217951049928
2000,125,0.1860668957233429,0.221534292840836,0.19050000011920928,0.22542002789524138,0.20747855234387827,0.23486863740548716,0.2101123488492694,0.23812206234555214
2000,250,0.1375974995084107,0.1779827709708895,0.14549999898299576,0.1861177032851443,0.13208075113756834,0.18358746637178316,0.13729587567493734,0.1906280360647414
2000,500,0.09030031156726182,0.15279076742578526,0.1004999996162951,0.16798766033381832,0.0819731391169257,0.1442896640064685,0.08959196500820175,0.15450134936342233
2000,1000,0.039112871114048174,0.11552928243668711,0.05049999924376607,0.13106786889233152,0.0418097709908522,0.12097845582471545,0.04829901536915729,0.13583310995149023
2000,2000,0.014181399666085781,0.1060499193869075,0.020499999541789292,0.12482676795702807,0.012383209497658554,0.10456863870375212,0.016293613505095058,0.12078140267524196
2000,4000,0.007018645483185537,0.08301587847574633,0.009499999787658453,0.11072852321881421,0.005270209578363026,0.08839169274011445,0.0062665411428028915,0.11518780224835766
2000,8000,0.005887662450550124,0.07143619114875185,0.0029999999329447745,0.10285476971493691,0.004810156696187145,0.07435998944061549,0.0027072045453056105,0.10499838479866246
2000,16000,0.0028259774480829947,0.06300330397729971,0.0004999999888241291,0.09276934042192843,0.002593620964897114,0.06408079394173917,0.00012600814428124804,0.09144782501512672

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN1L
  - Number of hidden layers: 1
  - Width of hidden layers: 500
  - Dataset type: mnist
  - Random labels: False
  - Training set size: 2000
  - Test set size: 9786
  - Minimum epochs: 4000
  - Number of Batches: 40
  - Beta values: [0.0, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
  - Learning rate (a0): 0.01
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
