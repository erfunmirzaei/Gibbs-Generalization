Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
2000,0.0,0.5600000023841858,0.6499999761581421,0.5600000023841858,0.6499999761581421,0.49563091094891226,0.5059743327812536,0.4957283176098505,0.5060217951049928
2000,125,0.2941648684442043,0.31047310816998386,0.2975000023841858,0.31446369342049774,0.30573329074516403,0.3047867087050309,0.3087211757452784,0.3072531091276917
2000,250,0.25714973751455544,0.2821471730665285,0.26100000012665986,0.28626483177043954,0.2451202544414321,0.2564685626613069,0.24846388974723668,0.2593795128905226
2000,500,0.19015265256166458,0.22016404956883315,0.19850000124424697,0.22958471747685452,0.19925420746273712,0.2277053245262881,0.20613045594860682,0.2337378245523302
2000,1000,0.12770828362554312,0.18328020835713466,0.13699999963864684,0.1938039874087791,0.13638203910400384,0.18235936956662407,0.1461922498201112,0.19179554855703376
2000,2000,0.08187963948585093,0.14084234400367251,0.08949999930337071,0.1526150929988647,0.07999130987642197,0.14417659207062117,0.08819579168345643,0.15574442445518732
2000,4000,0.045021916180849074,0.11562213575353428,0.05649999920278788,0.1343830086442889,0.047227893969596306,0.11946068640925833,0.05545146871650377,0.13879902516542134
2000,8000,0.026298825003323145,0.09400221808072255,0.029999999329447746,0.118279545054752,0.02400569622836584,0.09449871846839027,0.026738488249554916,0.11776706991102844
2000,16000,0.022140901745297016,0.07559149552668844,0.019499999564141036,0.0989606074076526,0.018725070152387585,0.07901906068198054,0.014806472801090136,0.10353553511610233

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: Savage
  - l_max: 4.0
  - Network architecture: FCN1L
  - Number of hidden layers: 1
  - Width of hidden layers: 500
  - Dataset type: mnist
  - Random labels: False
  - Training set size: 2000
  - Test set size: 9786
  - Minimum epochs: 4000
  - Number of Batches: 40
  - Beta values: [0.0, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
  - Learning rate (a0): 0.01
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
