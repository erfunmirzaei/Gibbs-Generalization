Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
1000,0.0,0.6200000643730164,0.3999999761581421,0.6200000047683716,0.4000000059604645,0.4997490121708582,0.4956751915608572,0.4997581910354612,0.49569268405627886
1000,125,0.41966448426246644,0.48632196899579494,0.43099999725818633,0.49702183050768717,0.4233612165371837,0.48432312855705023,0.4325600881583912,0.4922189773399763
1000,250,0.31666330993175507,0.4883929472796771,0.3370000019669533,0.5075344047984298,0.32933377223515276,0.49396455825147173,0.3422023172919279,0.50771360102479
1000,500,0.19232499673962594,0.4633946665087525,0.21399999782443047,0.4971404814598512,0.20164373227319493,0.4694415004392327,0.22563535783185606,0.5017613767154336
1000,1000,0.07950871819630265,0.45511697840933896,0.10499999914318323,0.5012411003818318,0.07684422094644555,0.45825744036265886,0.10164135883395005,0.5031502418956584
1000,2000,0.032294832705520096,0.4190143693466576,0.05199999883770943,0.49156620368665577,0.030308054939766783,0.42742213794884587,0.047814502164823296,0.49499720357203714
1000,4000,0.009565617237240077,0.4315448871680668,0.004999999888241291,0.5043355485006255,0.00924481146924917,0.4359940332800414,0.00702448603896322,0.5075432108898296
1000,8000,0.007075789291411639,0.4096212061692257,0.0009999999776482583,0.5010536273523253,0.007118276168473253,0.4127953759589689,0.0017488882632327712,0.5040406772408264
1000,16000,0.004807628120761365,0.39546901139677787,0.0,0.5048813415425164,0.0050014566538612824,0.39485073077391336,8.922196631347329e-21,0.5041874508700444

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN1L
  - Number of hidden layers: 1
  - Width of hidden layers: 500
  - Dataset type: mnist
  - Random labels: True
  - Training set size: 1000
  - Test set size: 9786
  - Minimum epochs: 4000
  - Number of Batches: 20
  - Beta values: [0.0, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
  - Learning rate (a0): 0.01
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
