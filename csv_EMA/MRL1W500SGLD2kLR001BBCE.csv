Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
2000,0.0,0.5800000429153442,0.4599999785423279,0.5799999833106995,0.46000000834465027,0.5070931511343186,0.5251609114876902,0.5071583236058379,0.52519911590833
2000,125,0.46219218969345094,0.4925055017276686,0.4684999994933605,0.5012553370728785,0.44963931548070135,0.49770287407089436,0.4546977791006568,0.5026377393267646
2000,250,0.40003976970911026,0.4506431897075809,0.4390000030398369,0.4911390570353489,0.4107798091203708,0.4804412895064557,0.42905591135231597,0.49764422447092227
2000,500,0.3232728034257889,0.4270637430706803,0.37749999910593035,0.48957759537258927,0.3434574823948351,0.45486117513829066,0.3736057779969741,0.4901082271096623
2000,1000,0.21264716256409882,0.3827074760076951,0.309000001847744,0.5049145659621881,0.2138801902577656,0.40616453301590116,0.29254010901290983,0.4982414580288013
2000,2000,0.13206461481750012,0.33886563595460384,0.2470000005327165,0.501072612039897,0.13029129969785783,0.37021513616126034,0.21742891785924578,0.5029716819664645
2000,4000,0.04545758068561554,0.3630897953194015,0.07299999948590993,0.4987944918019431,0.04846311459062401,0.381345230046669,0.08410102959088918,0.502642315760136
2000,8000,0.030587628344073893,0.34902809195372525,0.040499999187886715,0.4918865667922156,0.025096056884407865,0.36692854379914713,0.027519167636637542,0.5015530886221026
2000,16000,0.019266964751295745,0.33392040583552146,0.006999999843537807,0.49511864933432365,0.017821653234881805,0.34529037808834584,0.005503209438847737,0.5015151599663029

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN1L
  - Number of hidden layers: 1
  - Width of hidden layers: 500
  - Dataset type: mnist
  - Random labels: True
  - Training set size: 2000
  - Test set size: 9786
  - Minimum epochs: 4000
  - Number of Batches: 40
  - Beta values: [0.0, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
  - Learning rate (a0): 0.01
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
