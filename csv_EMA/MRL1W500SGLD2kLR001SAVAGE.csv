Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
2000,0.0,0.5799999833106995,0.46000000834465027,0.5799999833106995,0.46000000834465027,0.5071042033267752,0.5251782912787483,0.5071583236058379,0.52519911590833
2000,125,0.48039002567529676,0.49190739891966995,0.49000000283122064,0.49768865473416385,0.5016080259794837,0.49336420464157316,0.5043877582759918,0.4960448997420979
2000,250,0.4744034059345722,0.4935856838615573,0.4780000001192093,0.4972282836631853,0.47025484995969097,0.49214451228571693,0.4739562391749422,0.4952009740794513
2000,500,0.4395537041127682,0.4747551001456319,0.45999999791383744,0.49476269282856766,0.43997758416476507,0.4795645556772381,0.45280985485281566,0.4916644692405931
2000,1000,0.3733381800353527,0.44157115476472036,0.42850000113248826,0.4863763582341525,0.3809177288359215,0.46477791624861503,0.4120897207577873,0.5000002714198204
2000,2000,0.3127899430692196,0.3910186695201056,0.41249999925494196,0.4997959161291317,0.3168296885319163,0.428623619094341,0.38410704048951044,0.5002346133475216
2000,4000,0.24123562276363372,0.3549911218638323,0.33650000058114526,0.5004935894085436,0.22712699712864884,0.378786154501129,0.3096708306339923,0.5008970795763161
2000,8000,0.18777252547442913,0.3410082936895137,0.2689999993890524,0.49627432135903105,0.17222189124555898,0.35361507707403633,0.24116290947120483,0.49843810999718463
2000,16000,0.14695902019739152,0.3251858067755796,0.19950000010430813,0.5071096326015434,0.13259827786887154,0.33349194992411757,0.17041018180489664,0.49968923001551663

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: Savage
  - l_max: 4.0
  - Network architecture: FCN1L
  - Number of hidden layers: 1
  - Width of hidden layers: 500
  - Dataset type: mnist
  - Random labels: True
  - Training set size: 2000
  - Test set size: 9786
  - Minimum epochs: 4000
  - Number of Batches: 40
  - Beta values: [0.0, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
  - Learning rate (a0): 0.01
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
