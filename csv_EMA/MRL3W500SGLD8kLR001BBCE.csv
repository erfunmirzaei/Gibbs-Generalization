Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
8000,0.0,0.49000003933906555,0.5450000166893005,0.49000000953674316,0.5450000166893005,0.49781784246618604,0.497132869452256,0.4978178367886422,0.4971328520010558
8000,500,0.4962750535458326,0.49706901397023884,0.49637499526143075,0.4971428556101663,0.5053125311551719,0.5018754028734652,0.5053125301111295,0.50187540819174
8000,1000,0.24978736303746701,0.2509618343747392,0.5018749970942735,0.49347706534424607,0.47713820494087444,0.5013666248748688,0.4823874300822526,0.506088300607915
8000,2000,0.19464982952922583,0.2135071882179805,0.4564999990165234,0.4990816323124633,0.18398479540383064,0.2002811432214195,0.4814543503446415,0.5059502689112362
8000,4000,0.1847624320536852,0.21194902670626736,0.43324999809265136,0.5023392566612789,0.1764890569890282,0.20684728772100072,0.4283117332938181,0.49938035455207896
8000,8000,0.16070012021809815,0.2507831189705401,0.3437500009313226,0.49770902066814654,0.14856618467261354,0.2750091604451754,0.2986712614821903,0.4961362050627074
8000,16000,0.12376657212153078,0.25102233552202885,0.25487499944865705,0.49636493349561883,0.09112480726320638,0.30402793342497714,0.1710952208658827,0.5014683919137766
8000,32000,0.12537514828145505,0.21821814836287984,0.2636250006966293,0.504512834305666,0.08346699290152124,0.28001041714002206,0.1524314415436061,0.5034834520087786
8000,64000,0.09188188277184964,0.245669780641186,0.16374999936670065,0.504842000956438,0.053328120878652865,0.3160204707385723,0.0860416259254308,0.5034365479334627

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: FCN3L
  - Number of hidden layers: 3
  - Width of hidden layers: 500
  - Dataset type: mnist
  - Random labels: True
  - Training set size: 8000
  - Test set size: 9786
  - Minimum epochs: 4000
  - Number of Batches: 80
  - Beta values: [0.0, 500, 1000, 2000, 4000, 8000, 16000, 32000, 64000]
  - Learning rate (a0): 0.01
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
