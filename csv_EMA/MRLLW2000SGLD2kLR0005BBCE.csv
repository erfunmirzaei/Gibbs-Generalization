Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
2000,0.0,0.6399999856948853,0.44999998807907104,0.6399999856948853,0.44999998807907104,0.5008225490589295,0.49996494484727205,0.5008225303977716,0.4999649390047174
2000,125,0.1747837234288454,0.17151377137218202,0.5064999997615814,0.5022448946018608,0.1782890663054374,0.17606238023286003,0.5042885577674081,0.5017156430413761
2000,250,0.17199923433363437,0.17430179566144943,0.4964999988675117,0.49785713942683474,0.1743601628622358,0.1740683426217321,0.4876753016056751,0.502374503724057
2000,500,0.1817325558513403,0.18985717591582513,0.4749999962747097,0.5004603683340306,0.17932414102713715,0.18495841687391118,0.47569560918114123,0.5018046078475058
2000,1000,0.17149568870663642,0.18043535643694353,0.44699999690055847,0.49789036445471707,0.16984125217886195,0.1822412304244388,0.4472981195407407,0.5005461571665631
2000,2000,0.16755850575864314,0.17549424861766855,0.4459999993443489,0.5036378715719495,0.1673679154522339,0.17720637669162523,0.4403789924333711,0.5007644071565733
2000,4000,0.16478751897811889,0.17511512232678278,0.4364999994635582,0.496872324116376,0.1620965070541688,0.1794894833835721,0.39553525684096563,0.4972274913423919
2000,8000,0.16629360467195511,0.1708802126195966,0.4329999960958958,0.4972448972414951,0.16554910593043629,0.17210434394223012,0.43269181101620563,0.5040938171675426
2000,16000,0.16725371070206166,0.17087649979761668,0.4540000006556511,0.5022140452448203,0.1661301937400731,0.17101543413642015,0.4321571173422759,0.49930955402822513

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: LeNet5
  - Number of hidden layers: L
  - Width of hidden layers: 2000
  - Dataset type: mnist
  - Random labels: True
  - Training set size: 2000
  - Test set size: 9786
  - Minimum epochs: 4000
  - Number of Batches: 40
  - Beta values: [0.0, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
  - Learning rate (a0): 0.005
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
