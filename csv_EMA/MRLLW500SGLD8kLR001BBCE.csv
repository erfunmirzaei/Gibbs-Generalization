Sample_size,Beta,BCE_Train,BCE_Test,0-1_Train,0-1_Test,EMA_BCE_Train,EMA_BCE_Test,EMA_0-1_Train,EMA_0-1_Test
8000,0.0,0.5299999713897705,0.5600000023841858,0.5299999713897705,0.5600000023841858,0.49342791658213836,0.5020395078929576,0.4934279136566087,0.502039489349596
8000,500,0.17867142744362355,0.17573080014209358,0.5022499941289424,0.5025894203964545,0.1769661457299226,0.1796024532414451,0.49285083429404547,0.5001458846781691
8000,1000,0.1709696315228939,0.17125283120846263,0.5026249952614308,0.5005025188533627,0.17329889343053212,0.17307204592505415,0.5021948401641214,0.49906398462952983
8000,2000,0.17040062919259072,0.17084038348830477,0.4954999957233667,0.5029591820677932,0.1703665401709716,0.17001630352783037,0.506327790923125,0.5014819986988974
8000,4000,0.17071349918842316,0.17397360564494618,0.4792499981820583,0.504882597193426,0.17000651714256496,0.17352262977728838,0.4737193876791648,0.501472224457294
8000,8000,0.1688289765268564,0.17184147117089252,0.4629999965429306,0.49944919773510527,0.16862632677822403,0.17357348855814414,0.46116109762881236,0.5018151402185679
8000,16000,0.16795395109802486,0.17243905699982934,0.4544999968260527,0.511522930495593,0.16687446577288584,0.17427963971618057,0.44135852879372883,0.5116113949503123
8000,32000,0.16822267342358826,0.17025126455997935,0.4566249992698431,0.5005409230991286,0.16718550440913665,0.171374187830101,0.44949771730122284,0.5065277601997592
8000,64000,0.16884680651128292,0.16985966934233296,0.4662499953061342,0.5038852332806101,0.1684623564506624,0.1702473282611536,0.46295659096350333,0.5006180921531332

Summary:,"The LMC has been run with the following parameters:
  - Device: cpu
  - Loss function: BBCE
  - l_max: 4.0
  - Network architecture: LeNet5
  - Number of hidden layers: L
  - Width of hidden layers: 500
  - Dataset type: mnist
  - Random labels: True
  - Training set size: 8000
  - Test set size: 9786
  - Minimum epochs: 4000
  - Number of Batches: 80
  - Beta values: [0.0, 500, 1000, 2000, 4000, 8000, 16000, 32000, 64000]
  - Learning rate (a0): 0.01
  - Learning rate decay (b): 0.5
  - Gaussian prior sigma: 5
 -  alpha_average: 0.01
 -  alpha_stop: 0.00025
 -  eta: 0.1
 -  eps: 1e-07
 -  Gradient norm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"
